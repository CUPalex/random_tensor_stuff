{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training ResNet + TTRL on CIFAR-100\n",
    "This notebook contains the pipeline for training ResNet20 with the last layer substituted by TTRL (implementation can be found in models/ folder) on CIFAR-100 dataset. The training details are as in [Deep Residual Learning for Image Recognition, K. He et al](https://arxiv.org/pdf/1512.03385.pdf) and can be found in the last cell of the notebook.\n",
    "\n",
    "If you run this notebook as is, it will train five models with different values of theta (see implementation of TTRL for description of what theta is) and save them and some checkpoints in trained_models/ folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "# !pip install -U tensorly\n",
    "# !pip install -U tensorly-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tltorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as T\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar100_transform(train=True):\n",
    "    if train:\n",
    "        transform = T.Compose([\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761), inplace=True)\n",
    "\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "        ])\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_set = CIFAR100('CIFAR100', train=True, download=True,\n",
    "                    transform=get_cifar100_transform(train=True))\n",
    "test_set = CIFAR100('CIFAR100', train=False, download=True,\n",
    "                   transform=get_cifar100_transform(train=False))\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, pin_memory=True, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses_epoch(loss, accuracy, train_losses, test_losses, train_accuracies, test_accuracies):\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 8))\n",
    "    axs[0][0].plot(range(1, len(train_losses) + 1), train_losses, label='train')\n",
    "    axs[0][0].plot(range(1, len(test_losses) + 1), test_losses, label='test')\n",
    "    axs[0][0].set_ylabel('loss')\n",
    "    axs[0][0].set_xlabel('epoch')\n",
    "    axs[0][0].legend()\n",
    "\n",
    "    axs[0][1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label='train')\n",
    "    axs[0][1].plot(range(1, len(test_accuracies) + 1), test_accuracies, label='test')\n",
    "    axs[0][1].set_ylabel('accuracy')\n",
    "    axs[0][1].set_xlabel('epoch')\n",
    "    axs[0][1].legend()\n",
    "\n",
    "    axs[1][0].plot(range(1, len(loss) + 1), loss)\n",
    "    axs[1][0].set_ylabel('loss')\n",
    "    axs[1][0].set_xlabel('batch')\n",
    "\n",
    "    axs[1][1].plot(range(1, len(accuracy) + 1), accuracy)\n",
    "    axs[1][1].set_ylabel('accuracy')\n",
    "    axs[1][1].set_xlabel('batch')\n",
    "\n",
    "    for r_ax in axs:\n",
    "        for ax in r_ax:\n",
    "            ax.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, model, optimizer, train_loss, test_loss, test_accuracy, train_accuracy, path):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'test_loss' : test_loss,\n",
    "            'test_accuracy' : test_accuracy,\n",
    "            'train_accuracy' : train_accuracy\n",
    "            }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:3\", desc='Training...', train_losses=[], test_losses=[], train_accuracies=[], test_accuracies=[]):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    predicted_classes = torch.Tensor()\n",
    "    true_classes = torch.Tensor()\n",
    "\n",
    "    batch_num = 0\n",
    "\n",
    "    for images, labels in tqdm(train_dataloader, desc=desc):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses += [loss.item() * images.shape[0]]\n",
    "        predicted_classes = torch.cat((predicted_classes, (logits.argmax(dim=-1)).to('cpu')))\n",
    "        true_classes = torch.cat((true_classes, labels.to('cpu')))\n",
    "        accuracies += [(logits.argmax(dim=-1).to('cpu') == labels.to('cpu')).double().mean().item()]\n",
    "        \n",
    "        if batch_num % 50 == 0:\n",
    "            plot_losses_epoch(losses, accuracies, train_losses, test_losses, train_accuracies, test_accuracies)\n",
    "        batch_num += 1\n",
    "        \n",
    "    return losses, predicted_classes.tolist(), true_classes.tolist()\n",
    "\n",
    "\n",
    "def predict(model, val_dataloader, criterion, device=\"cuda:3\", desc='Evaluating...'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    val_losses = []\n",
    "    predicted_classes = torch.Tensor()\n",
    "    true_classes = torch.Tensor()\n",
    "\n",
    "    for images, labels in tqdm(val_dataloader, desc=desc):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "        \n",
    "        val_losses += [loss.item() * images.shape[0]]\n",
    "        predicted_classes = torch.cat((predicted_classes, (logits.argmax(dim=-1)).to('cpu')))\n",
    "        true_classes = torch.cat((true_classes, labels.to('cpu')))\n",
    "\n",
    "    return val_losses, predicted_classes.tolist(), true_classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_losses=[], test_losses=[], train_accuracies=[], test_accuracies=[]):\n",
    "    train_losses = train_losses\n",
    "    test_losses = test_losses\n",
    "    train_accuracies = train_accuracies\n",
    "    test_accuracies = test_accuracies\n",
    "\n",
    "    for epoch in range(start_epoch + 1, n_epochs + 1):\n",
    "        train_losses_epoch, train_predicted_classes, train_true_classes = train_one_epoch(model, train_loader, criterion, optimizer, device, f'Training {epoch}/{n_epochs}', train_losses, test_losses, train_accuracies, test_accuracies)\n",
    "        train_losses += [sum(train_losses_epoch) / len(train_losses_epoch)]\n",
    "        train_accuracies += [(torch.Tensor(train_predicted_classes) == torch.Tensor(train_true_classes)).type(torch.DoubleTensor).mean().item()]\n",
    "        \n",
    "        scheduler.step(epoch)\n",
    "\n",
    "        test_losses_epoch, test_predicted_classes, test_true_classes = predict(model, test_loader, criterion, device, f'Evaluating... {epoch}/{n_epochs}')\n",
    "        test_losses += [sum(test_losses_epoch) / len(test_losses_epoch)]\n",
    "        test_accuracies += [(torch.Tensor(test_predicted_classes) == torch.Tensor(test_true_classes)).type(torch.DoubleTensor).mean().item()]\n",
    "\n",
    "        if epoch % save_epoch == 0 and epoch > 0:\n",
    "            save_checkpoint(epoch=epoch, model=model, optimizer=optimizer, train_loss=train_losses, \\\n",
    "                test_loss=test_losses, test_accuracy=test_accuracies, train_accuracy=train_accuracies, \\\n",
    "                path= save_path + f'-epoch{epoch}.pt')\n",
    "    return train_losses, test_losses, train_accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../models')\n",
    "from resnet20_TTRL import resnet20_TTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "start_epoch = 60\n",
    "RESUME = False\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 180\n",
    "save_epoch = 40\n",
    "p_grid= [0.9, 0.8, 0.7, 0.6, 1]\n",
    "\n",
    "stats = []\n",
    "for p in p_grid:\n",
    "    if RESUME:\n",
    "        pass\n",
    "        # start_epoch, model, optimizer, train_losses, test_losses, train_acc, test_acc = load_checkpoint()\n",
    "    else:\n",
    "        model = resnet20_TTRL(device, p=p, rank='same', in_ttrl_shape=(4, 4, 4, 8, 8), out_ttrl_shape=(2, 5, 2, 5, 1)).to(device)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-1, weight_decay=1e-4, momentum=0.9)\n",
    "        train_losses, test_losses, train_acc, test_acc = [], [], [], []\n",
    "        start_epoch = 0\n",
    "    \n",
    "    import os\n",
    "    dir_path = f'trained_models/'\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    save_path = dir_path + f'TTRL-p-{p}'\n",
    "\n",
    "    milestones = [80, 120]\n",
    "    scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "    cur_train_losses, cur_test_losses, cur_train_accuracies, cur_test_accuracies = train(train_losses, test_losses, train_acc, test_acc)\n",
    "    stats.append({'train_losses' : cur_train_losses,\n",
    "                'test_losses' : cur_test_losses,\n",
    "                'train_accuracies' : cur_train_accuracies,\n",
    "                'test_accuracies' : cur_test_accuracies})\n",
    "    RESUME = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
